{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Visual Words Image Classification\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Pipeline\n",
    "\n",
    "The process is divided into 3 independent steps using a scikit `Pipeline`. Its input is a list of pictures, with the keypoints and the descriptors. The steps are:\n",
    "\n",
    "- SpatialPyramid: performs the clustering of the descriptors and calculates the histograms.\n",
    "- StandardScaler: standarizes each column of the feature matrix.\n",
    "- SVC: performs the classification.\n",
    "\n",
    "Internally, the pipeline uses a cache in order to speed up repeated operations.\n",
    "\n",
    "### GridSearchCV\n",
    "\n",
    "We use scikit-learn class `GridSearchCV` in order to compute the parameter combinations. Internally, it performs cross-validation with the different combinations and returns the best result or, in our case, a table with all the results. This table is then wrapped around a pandas `DataFrame` and returned.\n",
    "\n",
    "We are using 5 folds for the cross-validation and creating as many jobs as cores in the computer.\n",
    "\n",
    "### Histogram intersection kernel\n",
    "\n",
    "We use the following implementation for the histogram intersection kernel:\n",
    "\n",
    "```python\n",
    "def histogram_intersection_kernel(x, u):\n",
    "    n_samples, n_features = x.shape\n",
    "    K = np.zeros((x.shape[0], u.shape[0]), dtype=np.float32)\n",
    "    for d in range(n_samples):\n",
    "        K[d, :] = np.sum(np.minimum(x[d], u), axis=1)\n",
    "    return K\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from descriptors.histogram_intersection_kernel import histogram_intersection_kernel\n",
    "from main import main\n",
    "\n",
    "\n",
    "def run_experiment(param_grid: dict):\n",
    "    args = Namespace(train_path='../data/MIT_split/train',\n",
    "                     test_path='../data/MIT_split/test',\n",
    "                     cache_path='../.cache')\n",
    "    return main(args, param_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "#### Codebook sampling\n",
    "Since we run Dense SIFT with a small `step_size` and for several `scales` at each location, we get a great amount of descriptor vectors. But we don't need all of them for the construction of the codebook, we can get away with a random subset of those. In this experiment, we test different amounts of samples used for the creation of the codeebok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'transformer__n_samples': np.linspace(10000, 100000, 5, dtype=int),\n",
    "}\n",
    "results = run_experiment(param_grid)\n",
    "\n",
    "results.plot.line(x='param_transformer__n_samples', y='mean_test_score')\n",
    "plt.xlabel('samples')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment results above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codebook size\n",
    "In this experiment, we test different codebook sizes or, in other words, different number of clusters for the K-Means algorithm used to generate the codebook. We try sizes multiples of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'transformer__n_clusters': np.logspace(7, 10, 8, base=2, dtype=int),\n",
    "    'transformer__n_levels': [1]\n",
    "}\n",
    "results = run_experiment(param_grid)\n",
    "\n",
    "results.plot.line(x='param_transformer__n_clusters', y='mean_test_score')\n",
    "plt.xlabel('n_clusters')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment results above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization of descriptors\n",
    "In this experiment, we test different types of normalization of the descriptor vectors. We try L1-norm, L2-norm and Power-norm, which consists in applying to each dimension the following function:\n",
    "\n",
    "$f(z) = \\operatorname{sign}(z)|z|^{\\alpha}$\n",
    "\n",
    "where $0 \\leq \\alpha \\leq 1$ is a parameter of the normalization (https://www.robots.ox.ac.uk/~vgg/rg/papers/peronnin_etal_ECCV10.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'transformer__norm': ['l1', 'l2', 'power'],\n",
    "}\n",
    "results = run_experiment(param_grid)\n",
    "\n",
    "# Colormap needed until a bug is fixed in next version of pandas.\n",
    "results.plot.bar(x='param_transformer__norm', y='mean_test_score', colormap='jet')\n",
    "plt.xlabel('norm')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment results above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Pyramid levels\n",
    "In this experiment, we test different number of levels for the spatial pyramid that takes into account the location of the descriptors to generate a global image descriptor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'transformer__n_levels': np.linspace(1, 3, 3, dtype=int),\n",
    "}\n",
    "results = run_experiment(param_grid)\n",
    "\n",
    "# Colormap needed until a bug is fixed in next version of pandas.\n",
    "results.plot.bar(x='param_transformer__n_levels', y='mean_test_score', colormap='jet')\n",
    "plt.xlabel('n_levels')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment results above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel type and penalty parameter\n",
    "In this experiment, we test different kernels and values for the penalty parameter `C` of the error term of the classifier. We also investigate how different number of spatial pyramid levels may affect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'classifier__kernel': ['linear', 'rbf', 'sigmoid', histogram_intersection_kernel],\n",
    "    'classifier__C': np.logspace(-3, 15, 5, base=2),\n",
    "    'transformer__n_levels': [1, 2]\n",
    "}\n",
    "\n",
    "results = run_experiment(param_grid)\n",
    "results.loc[results.param_classifier__kernel == histogram_intersection_kernel, 'param_classifier__kernel'] = \\\n",
    "    \"histogram_intersection\"\n",
    "\n",
    "results.pivot(index='param_classifier__C', columns='param_classifier__kernel', values='mean_test_score') \\\n",
    "    .plot.line(logx=True)\n",
    "\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment results above. With `n_levels=1` RBF kernel should perform much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel type and kernel coefficient\n",
    "In this experiment, we test different kernels and values for the kernel coefficient `gamma` of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'classifier__kernel': ['linear', 'rbf', 'sigmoid', histogram_intersection_kernel],\n",
    "    'classifier__gamma': np.logspace(-15, 3, 5, base=2)\n",
    "}\n",
    "\n",
    "results = run_experiment(param_grid)\n",
    "results.loc[results.param_classifier__kernel == histogram_intersection_kernel, 'param_classifier__kernel'] = \\\n",
    "    \"histogram_intersection\"\n",
    "\n",
    "results.pivot(index='param_classifier__gamma', columns='param_classifier__kernel', values='mean_test_score') \\\n",
    "    .plot.line(logx=True)\n",
    "\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment results above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
