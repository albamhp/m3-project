;DEFAULTS
;batch_size: 16
;image_size: 64
;units: 2048,1024
;activation: relu,relu
;loss: categorical_crossentropy
;optimizer: sgd
;metrics: accuracy
;patches: False
;patch_size: 64

[Section-relu-1]
units: 4096
activation: relu

[Section-relu-2]
units: 2048
activation: relu

[Section-relu-3]
units: 1024
activation: relu

[Section-relu-4]
units: 512
activation: relu

[Section-relu-5]
units: 4096,2048

[Section-relu-6]
units: 2048,1024

[Section-relu-7]
units: 1024,512

[Section-relu-8]
units: 512,256

[Section-tanh-1]
units: 4096
activation: tanh

[Section-tanh-2]
units: 2048
activation: tanh

[Section-tanh-3]
units: 1024
activation: tanh

[Section-tanh-4]
units: 512
activation: tanh

[Section-tanh-5]
units: 4096,2048
activation: tanh,tanh

[Section-tanh-6]
units: 2048,1024
activation: tanh,tanh

[Section-tanh-7]
units: 1024,512
activation: tanh,tanh

[Section-tanh-8]
units: 512,256
activation: tanh,tanh

[Section-linear-1]
units: 4096
activation: linear

[Section-linear-2]
units: 2048
activation: linear

[Section-linear-3]
units: 1024
activation: linear

[Section-linear-4]
units: 512
activation: linear

[Section-linear-5]
units: 4096,2048
activation: linear,linear

[Section-linear-6]
units: 2048,1024
activation: linear,linear

[Section-linear-7]
units: 1024,512
activation: linear,linear

[Section-linear-8]
units: 512,256
activation: linear,linear

[Section-elu-1]
units: 4096
activation: elu

[Section-elu-2]
units: 2048
activation: elu

[Section-elu-3]
units: 1024
activation: elu

[Section-elu-4]
units: 512
activation: elu

[Section-elu-5]
units: 4096,2048
activation: elu,elu

[Section-elu-6]
units: 2048,1024
activation: elu,elu

[Section-elu-7]
units: 1024,512
activation: elu,elu

[Section-elu-8]
units: 512,256
activation: elu,elu

[Section-softmax-1]
units: 4096
activation: softmax

[Section-softmax-2]
units: 2048
activation: softmax

[Section-softmax-3]
units: 1024
activation: softmax

[Section-softmax-4]
units: 512
activation: softmax

[Section-softmax-5]
units: 4096,2048
activation: softmax,softmax

[Section-softmax-6]
units: 2048,1024
activation: softmax,softmax

[Section-softmax-7]
units: 1024,512
activation: softmax,softmax

[Section-softmax-8]
units: 512,256
activation: softmax,softmax

[Section-adam-1]
units: 4096
optimizer: adam
activation: relu

[Section-adam-2]
units: 2048
optimizer: adam
activation: relu

[Section-adam-3]
units: 1024
optimizer: adam
activation: relu

[Section-adam-4]
units: 512
optimizer: adam
activation: relu

[Section-adam-5]
units: 4096,2048
optimizer: adam

[Section-adam-6]
units: 2048,1024
optimizer: adam

[Section-adam-7]
units: 1024,512
optimizer: adam

[Section-adam-8]
units: 512,256
optimizer: adam

[Section-msq-1]
units: 4096
loss: mean_squared_error
activation: relu

[Section-msq-2]
units: 2048
loss: mean_squared_error
activation: relu

[Section-msq-3]
units: 1024
loss: mean_squared_error
activation: relu

[Section-msq-4]
units: 512
loss: mean_squared_error
activation: relu

[Section-msq-5]
units: 4096,2048
loss: mean_squared_error

[Section-msq-6]
units: 2048,1024
loss: mean_squared_error

[Section-msq-7]
units: 1024,512
loss: mean_squared_error

[Section-msq-8]
units: 512,256
loss: mean_squared_error

; 56
[Section-patches-1]
units: 4096
activation: relu
patches: True

[Section-patches-2]
units: 2048
activation: relu
patches: True

[Section-patches-3]
units: 1024
activation: relu
patches: True

[Section-patches-4]
units: 512
activation: relu
patches: True

[Section-patches-5]
units: 4096,2048
activation: relu,relu
patches: True

[Section-patches-6]
units: 2048,1024
activation: relu,relu
patches: True

[Section-patches-7]
units: 1024,512
activation: relu,relu
patches: True

[Section-patches-8]
units: 512,256
activation: relu,relu
patches: True

; 64
[Section-triple-relu-1]
units: 4096,2048,1024
activation: relu,relu,relu

[Section-triple-relu-2]
units: 2048,1024,512
activation: relu,relu,relu

[Section-triple-relu-3]
units: 1024,512,256
activation: relu,relu,relu

[Section-triple-relu-4]
units: 512,256,128
activation: relu,relu,relu

[Section-triple-tanh-1]
units: 4096,2048,1024
activation: tanh,tanh,tanh

[Section-triple-tanh-2]
units: 2048,1024,512
activation: tanh,tanh,tanh

[Section-triple-tanh-3]
units: 1024,512,256
activation: tanh,tanh,tanh

[Section-triple-tanh-4]
units: 512,256,128
activation: tanh,tanh,tanh

[Section-triple-linear-1]
units: 4096,2048,1024
activation: linear,linear,linear

[Section-triple-linear-2]
units: 2048,1024,512
activation: linear,linear,linear

[Section-triple-linear-3]
units: 1024,512,256
activation: linear,linear,linear

[Section-triple-linear-4]
units: 512,256,128
activation: linear,linear,linear

; 76
[Section-selu-1]
units: 4096
activation: selu

[Section-selu-2]
units: 2048
activation: selu

[Section-selu-3]
units: 1024
activation: selu

[Section-selu-4]
units: 512
activation: selu

[Section-selu-5]
units: 4096,2048
activation: selu,selu

[Section-selu-6]
units: 2048,1024
activation: selu,selu

[Section-selu-7]
units: 1024,512
activation: selu,selu

[Section-selu-8]
units: 512,256
activation: selu,selu

;84
